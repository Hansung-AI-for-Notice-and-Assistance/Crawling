{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6b3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from db import FileDB\n",
    "\n",
    "# DB 정의\n",
    "file_db = FileDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c011fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 정의\n",
    "\n",
    "# 세부적인 카테고리를 대표 카테고리로 통일하기 위한 map\n",
    "CATEGORY_MAP = {\n",
    "        # 취업\n",
    "        \"강소기업채용\" : \"취업\",\n",
    "        \"채용정보\" : \"취업\",\n",
    "        \"인턴쉽\" : \"취업\",\n",
    "        \"교육프로그램\" : \"취업\",\n",
    "        \"고시반\" : \"취업\",\n",
    "        \"기타\" : \"취업\",\n",
    "\n",
    "        # 장학\n",
    "        \"국가장학금\" : \"장학\",\n",
    "        \"교외장학금\" : \"장학\",\n",
    "        \"교내장학금\" : \"장학\",\n",
    "        \"면학근로\" : \"장학\",\n",
    "        \"학자금대출\" : \"장학\",\n",
    "        \"국가근로\" : \"장학\",\n",
    "        \"공모전 등\" : \"장학\",\n",
    "        \"비교과장학\" : \"장학\",\n",
    "\n",
    "        # 창업\n",
    "        \"창업정보\" : \"창업\",\n",
    "        \"창업공모전\" : \"창업\",\n",
    "        \"창업행사\" : \"창업\",\n",
    "        \"기타\" : \"창업\",\n",
    "    }\n",
    "# RSS 피드의 페이지 번호를 지정하기 위한 기본 URL. {} 부분에 숫자가 들어감.\n",
    "BASE_URL = 'https://www.hansung.ac.kr/bbs/hansung/143/rssList.do?page={}'\n",
    "# 상대 경로를 절대 경로로 변환할 때 사용할 기본 도메인\n",
    "BASE_DOMAIN = \"https://www.hansung.ac.kr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b9bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 정의\n",
    "\n",
    "# 카테고리 정규화 함수\n",
    "def normalize_category(category):\n",
    "    return CATEGORY_MAP.get(category, category)\n",
    "\n",
    "# 공지사항 게시글을 조회하여 내용, 사진, 첨부파일 수집하는 함수\n",
    "def html_croll(url, base_domain):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "\n",
    "    content, image_urls, attachments = \"\", [], []\n",
    "    \n",
    "    # 내용 및 사진\n",
    "    view_con_div = soup.find('div', class_='view-con')\n",
    "    if view_con_div:\n",
    "        content = view_con_div.get_text(strip=True) # 본문 텍스트 전체 가져오기\n",
    "        # 그 안의 모든 텍스트를 태그 제거 + 붙여서 가져옴\n",
    "        # 표(table)나 문단(p) 같은 게 전부 줄바꿈 없이 한 덩어리로 합쳐져 버림\n",
    "        \n",
    "        # 이미지 URL을 찾기 (content와 상관없이 이미지 URL을 추출)\n",
    "        for img_tag in view_con_div.find_all('img', src=True):\n",
    "            src = img_tag['src']\n",
    "            if src.startswith('/'):\n",
    "                src = f\"{base_domain}{src}\" # 기본 도메인 주소 사용\n",
    "            image_urls.append(src)\n",
    "    else:\n",
    "        content = \"No content found\"\n",
    "\n",
    "    # 첨부파일\n",
    "    file_div = soup.find('div', class_='view-file')\n",
    "    if file_div:\n",
    "        for a_tag in file_div.find_all('a', href=True):\n",
    "            href = a_tag['href']\n",
    "            # 다운로드 링크만 걸러내기\n",
    "            if \"download.do\" in href:\n",
    "                if href.startswith('/'):\n",
    "                    file_url = f\"{base_domain}{href}\"\n",
    "                file_name = a_tag.get_text(strip=True)\n",
    "                attachments.append(f\"{file_name} | {file_url}\") # 문자열로 합쳐서 저장\n",
    "    \n",
    "    return content, image_urls, attachments\n",
    "\n",
    "# RSS 피드를 순회하여 제목, 링크, 게시일, 카테고리 수집하는 함수\n",
    "def rss_croll(db, max_pages, base_url, base_domain):\n",
    "    saved_cnt = 0 # 저장된 공지사항 개수\n",
    "    image_only_count = 0 # 이미지만 있는 공지사항 개수\n",
    "\n",
    "    for page_number in range(1, max_pages+1):\n",
    "        url = base_url.format(page_number)\n",
    "        page = requests.get(url)\n",
    "        soup = bs(page.text, 'xml')\n",
    "        items = soup.find_all('item')\n",
    "\n",
    "        if not items:\n",
    "            print(f\"{page_number} 페이지에 더 이상 게시물이 없습니다.\")\n",
    "            break # 게시물이 없으면 중단\n",
    "\n",
    "        for item in items:\n",
    "            title = item.find('title').get_text(strip=True) if item.find('title') else \"No Title\"\n",
    "            link = item.find('link').get_text() if item.find('link') else \"No Link\"\n",
    "            pub_date = item.find('pubDate').get_text(strip=True) if item.find('pubDate') else \"No Date\"\n",
    "            category = item.find('category').get_text(strip=True) if item.find('category') else \"No Category\"\n",
    "\n",
    "            # 카테고리 정규화\n",
    "            category = normalize_category(category)\n",
    "\n",
    "            # 절대 경로로 변경\n",
    "            if link.startswith(\"/\"):\n",
    "                link = f\"{base_domain}{link}\"\n",
    "\n",
    "            # 내용, 사진, 첨부파일들\n",
    "            content, image_urls, attachments = html_croll(link, base_domain)\n",
    "\n",
    "            # 내용은 없고, 이미지 URL은 있는지 확인\n",
    "            if image_urls and content == \"\":\n",
    "                image_only_count += 1\n",
    "                print(f\"-> 이미지 전용 공지 발견: {title}\")\n",
    "\n",
    "            # '143/' 뒤에 오는 숫자 그룹을 찾는 정규표현식\n",
    "            match = re.search(r'143/(\\d+)', link)\n",
    "            notice_id = match.group(1)\n",
    "\n",
    "            # DB에 저장\n",
    "            db.save_notice(\n",
    "                notice_id=notice_id,\n",
    "                title=title,\n",
    "                link=link,\n",
    "                date=pub_date,\n",
    "                category=category,\n",
    "                content=content,\n",
    "                image_urls=image_urls,\n",
    "                attachments=attachments\n",
    "            )\n",
    "            saved_cnt += 1\n",
    "            \n",
    "    print(f\"총 {saved_cnt}개의 공지사항이 성공적으로 저장되었습니다!\")\n",
    "    print(f\"이미지만 있는 공지는 총 {image_only_count}개입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ecabf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 이미지 전용 공지 발견: 2026학년도 1학기 일어권 파견 교환학생 선발안내\n",
      "-> 이미지 전용 공지 발견: 2025년 세종시립청소년교향악단 예능단원 모집 안내\n",
      "-> 이미지 전용 공지 발견: 2025년 상반기분 통영시 대학생 학자금 이자 지원 신청 안내(9/22 마감)\n",
      "-> 이미지 전용 공지 발견: 2025년도 하반기 (재)달서인재육성장학재단 장학생 선발 안내(9/30 마감)\n",
      "-> 이미지 전용 공지 발견: 케이키친한상 카페 시식 및 운영 안내\n",
      "-> 이미지 전용 공지 발견: 2025년「도봉구 청년 사회첫출발 지원금」홍보\n",
      "-> 이미지 전용 공지 발견: 2025년도 (재)포항시장학회 귀뚜라미 장학생 선발 안내(9/18 마감)\n",
      "-> 이미지 전용 공지 발견: 2025년도 (재)포항시장학회 대학교 장학생 선발 안내(9/18 마감)\n",
      "-> 이미지 전용 공지 발견: 25년도 2학기 중소기업 취업연계 장학사업(희망사다리 1유형) 신규장학생 신청 안내 (~9/19 마감)\n",
      "-> 이미지 전용 공지 발견: 2025년도 익산사랑장학재단 장학생 선발 안내(9/10 마감)\n",
      "-> 이미지 전용 공지 발견: [2025학년도 2학기] 동아리박람회 & 개강축제 행사 안내\n",
      "-> 이미지 전용 공지 발견: [국제교류] 25-2 국제교류프로그램설명회\n",
      "-> 이미지 전용 공지 발견: 2025년도 (재)광산장학회 장학생 선발 공고(9/12 마감)\n",
      "-> 이미지 전용 공지 발견: 2025년 하반기 제23기 후기 삼원 장학생(시각디자인전공) 선발 안내(9/26 마감)\n",
      "-> 이미지 전용 공지 발견: 대학생이 반드시 지켜야 할 저작권 상식\n",
      "-> 이미지 전용 공지 발견: 2025년 충청남도평생교육인재육성진흥원 학자금 대출이자 지원사업 안내(9/26 마감)\n",
      "총 60개의 공지사항이 성공적으로 저장되었습니다!\n",
      "이미지만 있는 공지는 총 16개입니다.\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "\n",
    "page = 2\n",
    "\n",
    "rss_croll(\n",
    "    db=file_db,\n",
    "    max_pages=page,\n",
    "    base_url=BASE_URL,\n",
    "    base_domain=BASE_DOMAIN\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
